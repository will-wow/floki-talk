export { syntaxHighlighterPrism as theme } from "@mdx-deck/themes";

import { Notes, Image } from "mdx-deck";
import { Split, FullScreenCode } from "mdx-deck/layouts";
import BgImage from "./components/BgImage";
import BestFriendFinder from "./components/BestFriendFinder";

# Web Scraping With

![floki](assets/floki.svg)

Will Ockelmann-Wagner

wow@carbonfive.com | [github.com/will-wow](http://github.com/will-wow)

---

<BgImage src="assets/perfect-world.jpg">

# In a perfect world...

</BgImage>

---

# All data would be in JSON

<Notes>
  Anything you wanted to know would be avaialbe in an easy-to-parse format,
  ready for your programatic consumption.
</Notes>

---

<BgImage src="assets/real-world.jpg" opacity="0.5">

# In the real world...

</BgImage>

---

<Split>

# Sometimes all you have is a website

![space-jam](assets/space-jam.png)

</Split>

<Notes>

And you have to make due
Sadly we don't be scraping space jam today.
It's a national treasure, but that markup is way too hard to parse, I tried, sorry.
But generally, HTML might not be JSON, but it's still pretty structured, and
you can often programatically get the data you want.
It turns out a functional langage like Elixir is a really nice HTML parser
And a concurrent langage like elixir is a really nice HTML fetcher
which is why we're talking about this in an Elixir meetup

</Notes>

---

# Before we continue

<Notes>

One thing before we get into this

</Notes>

---

<Split>

# Please put away any black hats

![blackhat](assets/blackhat.png)

</Split>

<Notes>

Web scraping is one of those things that really useful, but often can be a little shady.
Don't scrape data you're not authorized to access, and don't accidentally
DDOS any sites

</Notes>

---

<Split>

# Basically don't make me do more of these

![captcha](assets/captcha.png)

</Split>

<Notes>

Basically dont' make me do more of these
Does the little sliver of sign count? No one knows.

</Notes>

---

# Floki: HTML Parser

<Notes>

Okay with that out of the way
So what is Floki? It is an HTML parser.
It takes some HTML, could be from a site or a file or whatever
Parses it into data structure
Finds elements, gets attributes, updates the structure
But is all just acting on HTML, not an actual web page

</Notes>

---

# Not Floki: Headless Browser

## Try Wallaby or Hound instead

<Notes>

That means that if what you want to do is fill out forms and click buttons
and stuff, you'll want something like Wallaby or Hound,
which run in a real browser.

The sweet spot for Floki is when you're gathering data, and gathering links that you can follow to get more data.

If you need to update something, you can always make a form POST with HTTPoison.

</Notes>

---

# Floki Data Structure

```elixir
Floki.parse(~s(
  <div id="main"><strong className="bold">Hello</strong> World</div>
))

{"div", [{"id", "main"}],
 [{"strong", [{"classname", "bold"}], ["Hello"]}, " World"]}
```

---

# Floki Querying and Parsing

```elixir
[friend_path | _] =
  html
  |> Floki.find(".friend")
  |> List.first()
  |> Floki.find("a.profile-link")
  |> Floki.attribute("href")
```

<Notes>

Pipelines

</Notes>

---

<Split>

<div>

# Example Scraping Target: IMDB

</div>

![nic-cage](assets/nic-cage.png)

</Split>

<Notes>

So today we're going to be scraping some data from IMDB
IMDB, suprisingly, doesn't have a public API
You can hit up OMDB - the Open Movie Database, which gets its data from... scraping IMDB

</Notes>

---

<Split>

<div>

# ExMDB

## Finding Actor Best Friends

</div>

![patrick-steward-ian-mckellen](assets/best-friends.jpg)

</Split>

---

# ExMDB

- Scrape IMDB
- Find an actor by name
- Find some movies they've been in
- Find who else has been in those movies
- Count up the co-stars
- ???
- Profit

---

# Here's that in code

```elixir
def find_best_friends(name, movie_count) do
  name
  |> Scraper.fetch_actor_path()
  |> Scraper.fetch_actor_movies(movie_count)
  |> Enum.flat_map(&Scraper.fetch_movie_actor_names/1)
  |> aggregate_friends(name)
end
```

<Notes>

Here's how that looks in code. Because Elixir, it's pretty much the same as it is in english

</Notes>

---

# Fetching and parsing

```elixir
def fetch_actor_path(actor_name) do
  "/find"
  |> fetch_page(q: actor_name, exact: true, s: "nm")
  |> Parser.find_actor_path()
end

def fetch_page(path, params \\ []) do
  "https://www.imdb.com#{path}"
  |> HTTPoison.get!([], params: params)
  |> Map.get(:body)
end
```

<Notes>

This is the pattern these scraper functions will genererally follow:

- use HTTPoison to GET a webpage
- get the body (just an HTML string)
- pass the body to a function that does Floki Parsing

</Notes>

---

# Why Seperate Parsers?

- Seperation of concerns
- Fetch once, parse twice
- Testing

---

# Seperate Parsers: Testing

```elixir
test "find_movie_actor_names" do
  html = File.read!("test/exmdb/movie.html")

  assert Parser.find_movie_actor_names(html) == ["Robert Downey Jr."]
end
```

<Notes>

Because parsers just operate on HTML strings and Floki data structures,
parsers are just pure functions, and pure functions are easy to test.

You can also test your fetcher logic, but then you have to deal with dependency injection,
or using Mox, or something like that. So splitting up those two things makes sense.

</Notes>

---

<Split>

# An Artist Page

![cap-filmography](assets/cap-filmography.png)

</Split>

<Notes>
  
So here's what the filmography section of an actor's page looks like
Each row in this table is a movie they're in, and the second cell has a link to the movie
page
which is what I want so I can see who was in that movie.
But, the ones with red text are still in production and often don't have the whole cast listed.
So I'd like to filter those out.

</Notes>

---

<Split>

# Pro-Tip: Disable JavaScript

![disable-js](assets/disable-js.png)

</Split>

---

# Parsing Movie Links (1)

```elixir
def find_actor_movies(actor_page, movie_count) do
  actor_page
  |> Floki.find(".filmo-category-section .filmo-row")
  |> Enum.filter(fn row ->
    # Filter out movies that may not
    # have a full cast list.
    Floki.find(row, ".in_production") == []
  end)
```

<Notes>

Find those movie rows, and filter out the ones that are in production

</Notes>

---

# Parsing Movie Links (2)

```elixir
  movie_rows
  |> Enum.take(movie_count)
  |> Enum.map(fn row ->
    row
    |> Floki.find("a")
    |> Floki.attribute("href")
    |> List.first()
  end)
end
```

<Notes>

- Then get just first few rows - I'm not trying to crawl all of IMDB here
- Finally for each row, get the first link in the row
- Gives us a list of links to follow to get the actors in all those movies

</Notes>

---

<BestFriendFinder />

<Notes>

Hopefully this works!
Here we can put in a name, and a number of movies, and it'll do the scraping
and give us back most frequent co-stars.

</Notes>

---


# Checks out

![cap-iron-man](assets/cap-iron-man.jpg)

---

# Async

```bash
➜  exmdb (master) ✗ time mix best_friends "Seth Rogen" 20 async
[
  {"James Franco", 4},
  {"Zac Efron", 3},
  {"Billy Eichner", 2},
  {"Nathan Fielder", 2},
  {"David Cross", 2},
  {"Lucy Liu", 2},
  {"Dave Franco", 2},
  {"Nick Kroll", 2},
  {"Randall Duk Kim", 2},
  {"Jack Black", 2}
]
mix best_friends "Seth Rogen" 20 async  4.50s user 0.69s system 62% cpu 8.348 total
➜  exmdb (master) ✗ time mix best_friends "Seth Rogen" 20
[
  {"James Franco", 4},
  {"Zac Efron", 3},
  {"Billy Eichner", 2},
  {"Nathan Fielder", 2},
  {"David Cross", 2},
  {"Lucy Liu", 2},
  {"Dave Franco", 2},
  {"Nick Kroll", 2},
  {"Randall Duk Kim", 2},
  {"Jack Black", 2}
]
mix best_friends "Seth Rogen" 20  3.81s user 0.55s system 16% cpu 25.886 total
```
